{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "frozen_lake.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyO4WiwwuPCTTO8Z/zU81mKH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nikhilreddy2002/FrozenLake-v0/blob/main/frozen_lake.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **FrozenLake-v0**\n",
        "<br>\n",
        "The agent controls the movement of a character in a grid world. Some tiles of the grid are walkable, and others lead to the agent falling into the water. Additionally, the movement direction of the agent is uncertain and only partially depends on the chosen direction. The agent is rewarded for finding a walkable path to a goal tile.\n",
        "<br>\n",
        "Link:  https://gym.openai.com/envs/FrozenLake-v0/"
      ],
      "metadata": {
        "id": "DqFZDCb1EcQW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "J9jvVh8jC5ST"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import gym\n",
        "import random\n",
        "import time\n",
        "from IPython.display import clear_output"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Creating Environment\n",
        "env = gym.make(\"FrozenLake-v0\") "
      ],
      "metadata": {
        "id": "nLlrVhyKF-_d"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#making Q-table\n",
        "state_space_size = env.observation_space.n\n",
        "action_space_size = env.action_space.n\n",
        "q_table = np.zeros((state_space_size,action_space_size))\n",
        "q_table"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7LGNkAPfGRFA",
        "outputId": "f53c4c23-75e2-4453-e088-89cc0aadc9a7"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_episodes = 10000\n",
        "max_steps_per_episode = 100\n",
        "\n",
        "learning_rate = 0.1\n",
        "discount_rate = 0.99\n",
        "\n",
        "exploration_rate = 1\n",
        "max_exploration_rate = 1\n",
        "min_exploration_rate = 0.01\n",
        "exploration_decay_rate = 0.001"
      ],
      "metadata": {
        "id": "-dXrwd3nHVVp"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rewards_all_episodes = []\n",
        "for episode in range(0,num_episodes):\n",
        "  state = env.reset()\n",
        "  done = False\n",
        "  rewards_for_the_current_episode = 0\n",
        "  for step in range(max_steps_per_episode):\n",
        "    #epsilon greedy strategy\n",
        "    exploration_rate_random = random.uniform(0,1)\n",
        "    if exploration_rate_random > exploration_rate:\n",
        "      action = np.argmax(q_table[state,:])\n",
        "    else:\n",
        "      action = env.action_space.sample()\n",
        "    #taking the next step\n",
        "    new_state, reward, done, info = env.step(action)\n",
        "    #updating Q table\n",
        "    q_table[state,action] = (1-learning_rate)*(q_table[state,action]) + learning_rate*(reward + discount_rate*(np.max(q_table[new_state,:])))\n",
        "    state = new_state\n",
        "    rewards_for_the_current_episode += reward\n",
        "    if done == True:\n",
        "      break\n",
        "  #updating exploration rate and rewards\n",
        "  exploration_rate = min_exploration_rate + (max_exploration_rate - min_exploration_rate)*np.exp(-exploration_decay_rate*episode)\n",
        "  rewards_all_episodes.append(rewards_for_the_current_episode)\n",
        "#Printing average reward\n",
        "rewards_per_thousand_episodes = np.split(np.array(rewards_all_episodes),num_episodes/1000)\n",
        "count = 1000\n",
        "print(\"********Average reward per thousand episodes********\\n\")\n",
        "for r in rewards_per_thousand_episodes:\n",
        "    print(count, \": \", str(sum(r/1000)))\n",
        "    count += 1000"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oNUphk44Ig6D",
        "outputId": "44298acb-f2f4-4c13-acd5-52e94d3ecf57"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "********Average reward per thousand episodes********\n",
            "\n",
            "1000 :  0.03900000000000003\n",
            "2000 :  0.17200000000000013\n",
            "3000 :  0.4070000000000003\n",
            "4000 :  0.5480000000000004\n",
            "5000 :  0.6420000000000005\n",
            "6000 :  0.6560000000000005\n",
            "7000 :  0.6710000000000005\n",
            "8000 :  0.6990000000000005\n",
            "9000 :  0.6640000000000005\n",
            "10000 :  0.6770000000000005\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(q_table)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hj2jJaPbV5nZ",
        "outputId": "28c3f40f-a5e3-4120-f748-1a7e36caa3a6"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.57695759 0.51784906 0.51608208 0.50871919]\n",
            " [0.39735985 0.28585045 0.35566082 0.51348129]\n",
            " [0.41736987 0.41313841 0.41678921 0.47088702]\n",
            " [0.36305345 0.26678322 0.34835851 0.45514028]\n",
            " [0.59832218 0.41204337 0.36729944 0.32051531]\n",
            " [0.         0.         0.         0.        ]\n",
            " [0.21151544 0.1452824  0.33854893 0.11612866]\n",
            " [0.         0.         0.         0.        ]\n",
            " [0.28499737 0.41429239 0.41601416 0.63898973]\n",
            " [0.34196811 0.67242248 0.44319677 0.30827074]\n",
            " [0.61093782 0.42196856 0.28396192 0.27041202]\n",
            " [0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.        ]\n",
            " [0.58809086 0.57061401 0.79313743 0.37518641]\n",
            " [0.72413694 0.90249424 0.75622204 0.74052027]\n",
            " [0.         0.         0.         0.        ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#visualizing The above code\n",
        "for episode in range(10):\n",
        "  state = env.reset()\n",
        "  done = False\n",
        "  print(\"*****EPISODE \", episode+1, \"*****\\n\\n\\n\\n\")\n",
        "  time.sleep(1)\n",
        "  for step in range (0,max_states_per_episode):\n",
        "    clear_output(wait = True)\n",
        "    env.render()\n",
        "    time.sleep(0.3)\n",
        "\n",
        "    action = np.argmax(q_table[state,:])\n",
        "    new_state, reward, done, info = env.step(action)\n",
        "\n",
        "    if done:\n",
        "      clear_output(wait=True)\n",
        "      env.render()\n",
        "      if reward == 1:\n",
        "        print(\"****You reached the goal!****\")\n",
        "        time.sleep(3)\n",
        "      else:\n",
        "        print(\"****You fell through a hole!****\")\n",
        "        time.sleep(3)\n",
        "      clear_output(wait=True)\n",
        "      break\n",
        "\n",
        "    state = new_state\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pl-3uJFSS5u7",
        "outputId": "8c634b53-4112-481f-f801-af1788eced95"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  (Down)\n",
            "SFFF\n",
            "FHFH\n",
            "FFFH\n",
            "HFF\u001b[41mG\u001b[0m\n",
            "****You reached the goal!****\n"
          ]
        }
      ]
    }
  ]
}